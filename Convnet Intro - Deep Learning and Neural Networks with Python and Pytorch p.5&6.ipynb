{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d3c1877",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "In recent years, CNNs have shown to outperform RNNs in sequential data. How does CNN work?\n",
    "- You pass the image in it's full form (no flatening required)\n",
    "- It can take 2D and 3D or N-D as inputs\n",
    "- Next, convoolutions are applied to the image. These are the kernels that pass through the image to detect features.\n",
    "- It can be seen as basically condensing the image into features.\n",
    "- The next step is pooling, most common of that is max pooling which typically just takes the maximum value of the window/kernel.\n",
    "- You have multiple layers of such convolutions. The first layer might be finding the most basic features like curves, edges, corners. The next layer has curves, corners and edges to start with and then it constructs features out of those like circles, squares and so on. The next layer finds the combination of circles and squares and stuff like that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53808dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "REBUILD_DATA = False # Flag to ensure that we don't build data everytime we run the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4886f767",
   "metadata": {},
   "source": [
    "Now, the image data is not uniform and we need to make the data normalized. So we make all the images of the size $50\\times 50$. We ignore the aspect ratio. We can also pad the image with white pixels if we wish to save the aspect ratio. Next step is to make a class for dogs vs cats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3261bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogsVSCats():\n",
    "    IMG_SIZE = 50\n",
    "    CATS = \"PetImages/Cat\"\n",
    "    DOGS = \"PetImages/Dog\"\n",
    "    TESTING = \"PetImages/Testing\"\n",
    "    LABELS = {CATS: 0, DOGS: 1}\n",
    "    training_data = []\n",
    "\n",
    "    catcount = 0\n",
    "    dogcount = 0\n",
    "\n",
    "    def make_training_data(self):\n",
    "        for label in self.LABELS:\n",
    "            print(label)\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                if \"jpg\" in f:\n",
    "                    try: # We do this because there is some problem with some of the images\n",
    "                        path = os.path.join(label, f)\n",
    "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) # We ask the question, is color (an added data) required to classify cats and dogs? if answer is no, then we try to simplify the model as much as possible\n",
    "                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE)) # We convert every image to 50X50 size\n",
    "                        self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])  # do something like print(np.eye(2)[1]), just makes one_hot \n",
    "                        #print(np.eye(2)[self.LABELS[label]])\n",
    "\n",
    "                        if label == self.CATS:\n",
    "                            self.catcount += 1\n",
    "                        elif label == self.DOGS:\n",
    "                            self.dogcount += 1\n",
    "\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                        #print(label, f, str(e))\n",
    "\n",
    "        np.random.shuffle(self.training_data)\n",
    "        np.save(\"training_data.npy\", self.training_data)\n",
    "        print('Cats:',dogsvcats.catcount) # Pretty sus for what we count but otherwise showing 0 for some reason\n",
    "        print('Dogs:',dogsvcats.dogcount)\n",
    "\n",
    "# Now we are ready to load the data\n",
    "if REBUILD_DATA:\n",
    "    dogsvcats = DogsVSCats()\n",
    "    dogsvcats.make_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91743226",
   "metadata": {},
   "source": [
    "Now, we are ready to run the code to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "939d21c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load(\"training_data.npy\", allow_pickle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e665e52e",
   "metadata": {},
   "source": [
    "We can do a sanity check of what we just saved and if it is in the right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44de3eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 73,  58,  72, ..., 115,  76,  61],\n",
      "        [ 72,  67,  66, ..., 118, 124,  62],\n",
      "        [ 66,  65,  66, ..., 130, 154,  68],\n",
      "        ...,\n",
      "        [ 84,  93,  62, ...,  65,  47,  52],\n",
      "        [ 91,  89,  72, ...,  52,  47,  53],\n",
      "        [ 85,  83,  80, ...,  58,  55,  55]], dtype=uint8) array([1., 0.])]\n"
     ]
    }
   ],
   "source": [
    "print(training_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b176d61c",
   "metadata": {},
   "source": [
    "The training_data\\[0\\] should be a cat as the 0th index is 1. Next, let's use matplotlib to see the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "658a593c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21c40b8bf10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(training_data[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7571e5",
   "metadata": {},
   "source": [
    "### Now we will finally proceede to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "881f6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) # inputs, Outputs and Kernel size\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "        \n",
    "        # Now at some point we would want to go to a linear layer. But that is tricky because we don't have a flatening function and we dont know how the dimensions will change\n",
    "        # self.fc1 = nn.Linear(?, 512) # This is how we need to proceede\n",
    "        # self.fc2 = nn.Linear(512, 2)\n",
    "                \n",
    "        # What we do is just pass random data and check the dimension that should replace the '?'\n",
    "        x = torch.randn(50,50).view(-1, 1, 50, 50) # 50*50 is the image size, 1 is the input to the conv1\n",
    "        self._to_linear = None # We will populate this to the dimension that is needed\n",
    "        self.convs(x) # This convs will serve as forward method but is actually not the forward method\n",
    "        \n",
    "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "\n",
    "        \n",
    "    def convs(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2)) # (2,2) is the shape of pooling layer\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2,2))\n",
    "        \n",
    "        # print (x[0].shape)\n",
    "        if self._to_linear == None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x) # Instead of writing the 3 pooling layers again, we just write the function # Convolutional Layers\n",
    "        # Since self._to_linear got populated, it's no longer None\n",
    "        x = x.view(-1, self._to_linear)\n",
    "        x = F.relu(self.fc1(x)) # Linear layers\n",
    "        x = self.fc2(x) # Final linear layer to output cat/dog\n",
    "        \n",
    "        return F.softmax(x, dim = 1) # The x is a batch of data, so how will you reference the batches? The 0th dimensions will be all of the batches, so dim = 1 is required to specify the classification points\n",
    "      \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c7588c",
   "metadata": {},
   "source": [
    "Now we can start ot train and input the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d51eb51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "X = torch.Tensor(np.array([i[0] for i in training_data])).view(-1, 50, 50) # We are making a numpy array of the list because it is extreemely slow to convert a list to tensor (got as a warning)\n",
    "X = X/255.0 # To scale the values to lie in 0 to 1\n",
    "y = torch.Tensor(np.array([i[1] for i in training_data])) \n",
    "\n",
    "VAL_PCT = 0.1 # Value percent - testing for 10% of our dataset\n",
    "val_size = int(len(X)*VAL_PCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98c95db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22452\n",
      "2494\n"
     ]
    }
   ],
   "source": [
    "train_X = X[:-val_size]\n",
    "test_X = X[-val_size:]\n",
    "\n",
    "train_y = y[:-val_size]\n",
    "test_y = y[-val_size:]\n",
    "\n",
    "print(len(train_X))\n",
    "print(len(test_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f36d704",
   "metadata": {},
   "source": [
    "Now, making the actual batches of the training data.\n",
    "\n",
    "### Let's revisit alll the data and see which is which"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88c5f3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2863, 0.2275, 0.2824,  ..., 0.4510, 0.2980, 0.2392],\n",
       "         [0.2824, 0.2627, 0.2588,  ..., 0.4627, 0.4863, 0.2431],\n",
       "         [0.2588, 0.2549, 0.2588,  ..., 0.5098, 0.6039, 0.2667],\n",
       "         ...,\n",
       "         [0.3294, 0.3647, 0.2431,  ..., 0.2549, 0.1843, 0.2039],\n",
       "         [0.3569, 0.3490, 0.2824,  ..., 0.2039, 0.1843, 0.2078],\n",
       "         [0.3333, 0.3255, 0.3137,  ..., 0.2275, 0.2157, 0.2157]],\n",
       "\n",
       "        [[0.4588, 0.4588, 0.4275,  ..., 0.3569, 0.3490, 0.3765],\n",
       "         [0.4549, 0.4627, 0.4510,  ..., 0.3804, 0.3608, 0.3882],\n",
       "         [0.4980, 0.4706, 0.4784,  ..., 0.3765, 0.3804, 0.3922],\n",
       "         ...,\n",
       "         [0.0235, 0.0039, 0.0078,  ..., 0.8941, 0.8784, 0.8667],\n",
       "         [0.0627, 0.0118, 0.0118,  ..., 0.8745, 0.8588, 0.8667],\n",
       "         [0.0784, 0.0392, 0.0078,  ..., 0.8667, 0.8431, 0.8431]],\n",
       "\n",
       "        [[0.3137, 0.0431, 0.0588,  ..., 0.0902, 0.1255, 0.2196],\n",
       "         [0.2863, 0.2431, 0.1294,  ..., 0.9020, 0.0039, 0.1294],\n",
       "         [0.2392, 0.2039, 0.1686,  ..., 0.3490, 0.0118, 0.1412],\n",
       "         ...,\n",
       "         [0.0784, 0.0196, 0.0627,  ..., 0.0549, 0.0314, 0.0431],\n",
       "         [0.1882, 0.0392, 0.0667,  ..., 0.0275, 0.0510, 0.0471],\n",
       "         [0.4431, 0.0667, 0.1020,  ..., 0.0314, 0.0392, 0.2745]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.4078, 0.4706, 0.3412,  ..., 0.3333, 0.4078, 0.4745],\n",
       "         [0.4392, 0.4196, 0.2980,  ..., 0.3686, 0.3686, 0.2784],\n",
       "         [0.3059, 0.2706, 0.2863,  ..., 0.2353, 0.2392, 0.3137],\n",
       "         ...,\n",
       "         [0.9412, 0.9647, 0.9804,  ..., 0.5843, 0.5961, 0.6078],\n",
       "         [0.8902, 0.9804, 0.9804,  ..., 0.6784, 0.6980, 0.6627],\n",
       "         [0.9765, 0.9804, 0.9804,  ..., 0.7137, 0.7451, 0.7098]],\n",
       "\n",
       "        [[0.4235, 0.3804, 0.3882,  ..., 0.4275, 0.1686, 0.1608],\n",
       "         [0.4353, 0.3922, 0.3882,  ..., 0.4314, 0.1490, 0.1804],\n",
       "         [0.4275, 0.3922, 0.3804,  ..., 0.4314, 0.1647, 0.3569],\n",
       "         ...,\n",
       "         [0.4980, 0.4706, 0.4824,  ..., 0.4196, 0.4118, 0.4039],\n",
       "         [0.4824, 0.5059, 0.4824,  ..., 0.4275, 0.4314, 0.4118],\n",
       "         [0.5216, 0.5137, 0.5059,  ..., 0.4431, 0.4353, 0.4510]],\n",
       "\n",
       "        [[0.8235, 0.8275, 0.8157,  ..., 0.2588, 0.2431, 0.2549],\n",
       "         [0.8196, 0.8314, 0.8157,  ..., 0.2627, 0.2667, 0.2784],\n",
       "         [0.8157, 0.8275, 0.8000,  ..., 0.2784, 0.2745, 0.2745],\n",
       "         ...,\n",
       "         [0.4353, 0.4471, 0.4627,  ..., 0.4627, 0.4627, 0.4588],\n",
       "         [0.4471, 0.4275, 0.4235,  ..., 0.4588, 0.4471, 0.4667],\n",
       "         [0.4431, 0.4471, 0.4392,  ..., 0.4627, 0.4745, 0.4667]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47ea04c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2863, 0.2275, 0.2824,  ..., 0.4510, 0.2980, 0.2392],\n",
       "        [0.2824, 0.2627, 0.2588,  ..., 0.4627, 0.4863, 0.2431],\n",
       "        [0.2588, 0.2549, 0.2588,  ..., 0.5098, 0.6039, 0.2667],\n",
       "        ...,\n",
       "        [0.3294, 0.3647, 0.2431,  ..., 0.2549, 0.1843, 0.2039],\n",
       "        [0.3569, 0.3490, 0.2824,  ..., 0.2039, 0.1843, 0.2078],\n",
       "        [0.3333, 0.3255, 0.3137,  ..., 0.2275, 0.2157, 0.2157]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7293bba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        ...,\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "687f56bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29e7657d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([22452, 50, 50]), torch.Size([22452, 2]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.size(), train_y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d35cc3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [01:11<00:00,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2348, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100 # If you get a memory error, always anywhere lower the batch size\n",
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
    "        # print(i, i+BATCH_SIZE)\n",
    "        batch_X = train_X[i:i+BATCH_SIZE].view(-1,1,50,50)\n",
    "        batch_y = train_y[i:i+BATCH_SIZE]\n",
    "        \n",
    "        # Now we plan to do a fitnet, and whenever we do that, we need to zero the gradients\n",
    "        # You can use model.zero_grad (our model is net) or optimizer.zero_grad, the difference between the two is based on the parameters that optimizer controls, in this case it controls all the parameters, no there's no difference\n",
    "        # There might be a case where we have 2 models with different optimizers on each side. We have to choose the way to do it based on the case\n",
    "        net.zero_grad() # Is the safest way to do\n",
    "        outputs = net(batch_X)\n",
    "        loss = loss_function(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4719aea",
   "metadata": {},
   "source": [
    "Checking out how the new batched data looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf28219d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1333, 0.1451, 0.1020,  ..., 0.0784, 0.0824, 0.0588],\n",
       "          [0.1137, 0.1412, 0.1608,  ..., 0.1843, 0.0980, 0.0745],\n",
       "          [0.0980, 0.1294, 0.2471,  ..., 0.0902, 0.0941, 0.0745],\n",
       "          ...,\n",
       "          [0.8157, 0.7843, 0.7804,  ..., 0.7020, 0.6588, 0.6431],\n",
       "          [0.8078, 0.7882, 0.7765,  ..., 0.5882, 0.6588, 0.6431],\n",
       "          [0.8196, 0.8510, 0.8588,  ..., 0.6039, 0.6588, 0.6627]]],\n",
       "\n",
       "\n",
       "        [[[0.3882, 0.3882, 0.3922,  ..., 0.3804, 0.3765, 0.3686],\n",
       "          [0.3961, 0.3961, 0.4000,  ..., 0.3804, 0.3725, 0.3686],\n",
       "          [0.4000, 0.4000, 0.4039,  ..., 0.3843, 0.3804, 0.3725],\n",
       "          ...,\n",
       "          [0.5255, 0.5333, 0.5412,  ..., 0.3804, 0.3725, 0.3686],\n",
       "          [0.5255, 0.5333, 0.5412,  ..., 0.4431, 0.4314, 0.4039],\n",
       "          [0.5294, 0.5373, 0.5412,  ..., 0.4784, 0.4706, 0.4471]]],\n",
       "\n",
       "\n",
       "        [[[0.7843, 0.7843, 0.7647,  ..., 0.1333, 0.2784, 0.3882],\n",
       "          [0.7569, 0.8039, 0.7647,  ..., 0.1176, 0.1451, 0.3137],\n",
       "          [0.3765, 0.8078, 0.8039,  ..., 0.2863, 0.2000, 0.2039],\n",
       "          ...,\n",
       "          [0.4118, 0.4078, 0.4353,  ..., 0.4706, 0.4431, 0.1961],\n",
       "          [0.4863, 0.4667, 0.4471,  ..., 0.5176, 0.3647, 0.1961],\n",
       "          [0.4706, 0.4745, 0.4431,  ..., 0.5176, 0.2235, 0.2118]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.4078, 0.4706, 0.3412,  ..., 0.3333, 0.4078, 0.4745],\n",
       "          [0.4392, 0.4196, 0.2980,  ..., 0.3686, 0.3686, 0.2784],\n",
       "          [0.3059, 0.2706, 0.2863,  ..., 0.2353, 0.2392, 0.3137],\n",
       "          ...,\n",
       "          [0.9412, 0.9647, 0.9804,  ..., 0.5843, 0.5961, 0.6078],\n",
       "          [0.8902, 0.9804, 0.9804,  ..., 0.6784, 0.6980, 0.6627],\n",
       "          [0.9765, 0.9804, 0.9804,  ..., 0.7137, 0.7451, 0.7098]]],\n",
       "\n",
       "\n",
       "        [[[0.4235, 0.3804, 0.3882,  ..., 0.4275, 0.1686, 0.1608],\n",
       "          [0.4353, 0.3922, 0.3882,  ..., 0.4314, 0.1490, 0.1804],\n",
       "          [0.4275, 0.3922, 0.3804,  ..., 0.4314, 0.1647, 0.3569],\n",
       "          ...,\n",
       "          [0.4980, 0.4706, 0.4824,  ..., 0.4196, 0.4118, 0.4039],\n",
       "          [0.4824, 0.5059, 0.4824,  ..., 0.4275, 0.4314, 0.4118],\n",
       "          [0.5216, 0.5137, 0.5059,  ..., 0.4431, 0.4353, 0.4510]]],\n",
       "\n",
       "\n",
       "        [[[0.8235, 0.8275, 0.8157,  ..., 0.2588, 0.2431, 0.2549],\n",
       "          [0.8196, 0.8314, 0.8157,  ..., 0.2627, 0.2667, 0.2784],\n",
       "          [0.8157, 0.8275, 0.8000,  ..., 0.2784, 0.2745, 0.2745],\n",
       "          ...,\n",
       "          [0.4353, 0.4471, 0.4627,  ..., 0.4627, 0.4627, 0.4588],\n",
       "          [0.4471, 0.4275, 0.4235,  ..., 0.4588, 0.4471, 0.4667],\n",
       "          [0.4431, 0.4471, 0.4392,  ..., 0.4627, 0.4745, 0.4667]]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1eaf4529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1333, 0.1451, 0.1020,  ..., 0.0784, 0.0824, 0.0588],\n",
       "         [0.1137, 0.1412, 0.1608,  ..., 0.1843, 0.0980, 0.0745],\n",
       "         [0.0980, 0.1294, 0.2471,  ..., 0.0902, 0.0941, 0.0745],\n",
       "         ...,\n",
       "         [0.8157, 0.7843, 0.7804,  ..., 0.7020, 0.6588, 0.6431],\n",
       "         [0.8078, 0.7882, 0.7765,  ..., 0.5882, 0.6588, 0.6431],\n",
       "         [0.8196, 0.8510, 0.8588,  ..., 0.6039, 0.6588, 0.6627]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "634d715b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([52, 1, 50, 50]), torch.Size([1, 50, 50]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_X.size(), batch_X[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "410b4a1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a9df7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dabe1aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([52, 2]), torch.Size([2]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y.size(), batch_y[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32961db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2494/2494 [00:04<00:00, 555.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(test_X))):\n",
    "        real_class = torch.argmax(test_y[i])\n",
    "        net_out = net(test_X[i].view(-1, 1, 50, 50))[0]\n",
    "        predicted_class = torch.argmax(net_out)\n",
    "        if predicted_class == real_class:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        \n",
    "accuracy = correct/total\n",
    "print(\"Accuracy: \", round(accuracy, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
