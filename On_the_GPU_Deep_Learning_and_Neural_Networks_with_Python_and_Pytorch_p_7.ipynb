{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "On the GPU - Deep Learning and Neural Networks with Python and Pytorch p.7",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "i5F824UXHOvi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "REBUILD_DATA = False # Flag to ensure that we don't build data everytime we run the code\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DogsVSCats():\n",
        "    IMG_SIZE = 50\n",
        "    CATS = \"PetImages/Cat\"\n",
        "    DOGS = \"PetImages/Dog\"\n",
        "    TESTING = \"PetImages/Testing\"\n",
        "    LABELS = {CATS: 0, DOGS: 1}\n",
        "    training_data = []\n",
        "\n",
        "    catcount = 0\n",
        "    dogcount = 0\n",
        "\n",
        "    def make_training_data(self):\n",
        "        for label in self.LABELS:\n",
        "            print(label)\n",
        "            for f in tqdm(os.listdir(label)):\n",
        "                if \"jpg\" in f:\n",
        "                    try: # We do this because there is some problem with some of the images\n",
        "                        path = os.path.join(label, f)\n",
        "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) # We ask the question, is color (an added data) required to classify cats and dogs? if answer is no, then we try to simplify the model as much as possible\n",
        "                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE)) # We convert every image to 50X50 size\n",
        "                        self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])  # do something like print(np.eye(2)[1]), just makes one_hot \n",
        "                        #print(np.eye(2)[self.LABELS[label]])\n",
        "\n",
        "                        if label == self.CATS:\n",
        "                            self.catcount += 1\n",
        "                        elif label == self.DOGS:\n",
        "                            self.dogcount += 1\n",
        "\n",
        "                    except Exception as e:\n",
        "                        pass\n",
        "                        #print(label, f, str(e))\n",
        "\n",
        "        np.random.shuffle(self.training_data)\n",
        "        np.save(\"training_data.npy\", self.training_data)\n",
        "        print('Cats:',dogsvcats.catcount) # Pretty sus for what we count but otherwise showing 0 for some reason\n",
        "        print('Dogs:',dogsvcats.dogcount)\n",
        "\n"
      ],
      "metadata": {
        "id": "Tnwbc5UcIN29"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we are ready to load the data\n",
        "if REBUILD_DATA:\n",
        "    dogsvcats = DogsVSCats()\n",
        "    dogsvcats.make_training_data()\n",
        "\n",
        "training_data = np.load(\"training_data.npy\", allow_pickle=True)\n",
        "print(training_data[0])\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5) # inputs, Outputs and Kernel size\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
        "        \n",
        "        # Now at some point we would want to go to a linear layer. But that is tricky because we don't have a flatening function and we dont know how the dimensions will change\n",
        "        # self.fc1 = nn.Linear(?, 512) # This is how we need to proceede\n",
        "        # self.fc2 = nn.Linear(512, 2)\n",
        "                \n",
        "        # What we do is just pass random data and check the dimension that should replace the '?'\n",
        "        x = torch.randn(50,50).view(-1, 1, 50, 50) # 50*50 is the image size, 1 is the input to the conv1\n",
        "        self._to_linear = None # We will populate this to the dimension that is needed\n",
        "        self.convs(x) # This convs will serve as forward method but is actually not the forward method\n",
        "        \n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.fc2 = nn.Linear(512, 2)\n",
        "\n",
        "        \n",
        "    def convs(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2)) # (2,2) is the shape of pooling layer\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), (2,2))\n",
        "        \n",
        "        # print (x[0].shape)\n",
        "        if self._to_linear == None:\n",
        "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
        "        return x\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.convs(x) # Instead of writing the 3 pooling layers again, we just write the function # Convolutional Layers\n",
        "        # Since self._to_linear got populated, it's no longer None\n",
        "        x = x.view(-1, self._to_linear)\n",
        "        x = F.relu(self.fc1(x)) # Linear layers\n",
        "        x = self.fc2(x) # Final linear layer to output cat/dog\n",
        "        \n",
        "        return F.softmax(x, dim = 1) # The x is a batch of data, so how will you reference the batches? The 0th dimensions will be all of the batches, so dim = 1 is required to specify the classification points\n",
        "      \n",
        "net = Net()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dOdSZvPImq4",
        "outputId": "a156241c-267a-4d03-d00f-479922ca6bd5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[ 73,  58,  72, ..., 115,  76,  61],\n",
            "       [ 72,  67,  66, ..., 118, 124,  62],\n",
            "       [ 66,  65,  66, ..., 130, 154,  68],\n",
            "       ...,\n",
            "       [ 84,  93,  62, ...,  65,  47,  52],\n",
            "       [ 91,  89,  72, ...,  52,  47,  53],\n",
            "       [ 85,  83,  80, ...,  58,  55,  55]], dtype=uint8)\n",
            " array([1., 0.])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check if cuda is available for us, we can use the following line"
      ],
      "metadata": {
        "id": "Jscz6LBGJCzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAPki50TIp2e",
        "outputId": "1cb828c7-f132-44d5-fc5e-70b22a67dd78"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEYXnE0PJBhq",
        "outputId": "d116c6e6-ae66-4eba-f4de-8c1c1195631f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can write a short code to set the device if cuda is available:"
      ],
      "metadata": {
        "id": "A5as35zVK8S_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda:0\")\n",
        "  print(\"Running on the GPU\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"Running on the CPU\")"
      ],
      "metadata": {
        "id": "4IT9bZstJX1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's easy in Pytorch to assign multiple layers to multiple GPUs and really common taks is like an encoder and decoder network."
      ],
      "metadata": {
        "id": "QHFqXvBbLc2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.device_count() # To check how many GPUs we actually have"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFFcG8F4LuZT",
        "outputId": "ec3bb82d-86d8-4482-b81a-87bf3b381268"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can take our entire neural network to the devise that we just set using. Tensors on the GPU can only interact with the tensors on the GPU, you can't cross interact, you will have to convert and put them exactly where you want them."
      ],
      "metadata": {
        "id": "c8LgTOqmL6sL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net.to(device) # Or net = Net().to(device) whenever we define net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-OMZ9OOLx2n",
        "outputId": "5d677b2c-1fc4-4428-e29a-9585246b958f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.Tensor(np.array([i[0] for i in training_data])).view(-1, 50, 50) # We are making a numpy array of the list because it is extreemely slow to convert a list to tensor (got as a warning)\n",
        "X = X/255.0 # To scale the values to lie in 0 to 1\n",
        "y = torch.Tensor(np.array([i[1] for i in training_data])) \n",
        "\n",
        "VAL_PCT = 0.1 # Value percent - testing for 10% of our dataset\n",
        "val_size = int(len(X)*VAL_PCT)"
      ],
      "metadata": {
        "id": "hgl-eskLO355"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = X[:-val_size]\n",
        "test_X = X[-val_size:]\n",
        "\n",
        "train_y = y[:-val_size]\n",
        "test_y = y[-val_size:]\n",
        "\n",
        "print(len(train_X))\n",
        "print(len(test_X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLYepEwOO5VM",
        "outputId": "6df196b6-df5f-4eb5-a4fe-8afeefe940a3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22452\n",
            "2494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 100 # If you get a memory error, always anywhere lower the batch size\n",
        "EPOCHS = 10\n",
        "\n",
        "def train(net):\n",
        "  optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "  loss_function = nn.MSELoss()\n",
        "  for epoch in range(EPOCHS):\n",
        "      for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
        "          # print(i, i+BATCH_SIZE)\n",
        "          batch_X = train_X[i:i+BATCH_SIZE].view(-1,1,50,50).to(device) # We add .to(device) here to take the data to the GPU\n",
        "          batch_y = train_y[i:i+BATCH_SIZE].to(device) # We add .to(device) here to take the data to the GPU\n",
        "          \n",
        "          # Now we plan to do a fitnet, and whenever we do that, we need to zero the gradients\n",
        "          # You can use model.zero_grad (our model is net) or optimizer.zero_grad, the difference between the two is based on the parameters that optimizer controls, in this case it controls all the parameters, no there's no difference\n",
        "          # There might be a case where we have 2 models with different optimizers on each side. We have to choose the way to do it based on the case\n",
        "          net.zero_grad() # Is the safest way to do\n",
        "          outputs = net(batch_X)\n",
        "          loss = loss_function(outputs, batch_y)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "      print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
        "\n",
        "def test(net):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for i in tqdm(range(len(test_X))):\n",
        "          real_class = torch.argmax(test_y[i]).to(device) # We send the testing to the device as well\n",
        "          net_out = net(test_X[i].view(-1, 1, 50, 50).to(device))[0] # We need test_X to be on the device as well\n",
        "          predicted_class = torch.argmax(net_out)\n",
        "          if predicted_class == real_class:\n",
        "              correct += 1\n",
        "          total += 1\n",
        "          \n",
        "  accuracy = correct/total\n",
        "  print(\"\")\n",
        "  print(\"Accuracy: \", round(accuracy, 3))\n",
        "\n",
        "\n",
        "train(net)\n",
        "test(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvSCvSBTMDyS",
        "outputId": "036f2749-b0eb-473b-e0ab-bff98ff4902d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 225/225 [00:01<00:00, 133.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0. Loss: 0.16294144093990326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 225/225 [00:01<00:00, 141.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1. Loss: 0.13670778274536133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 225/225 [00:01<00:00, 141.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2. Loss: 0.09709067642688751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 225/225 [00:01<00:00, 141.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3. Loss: 0.07227069139480591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 225/225 [00:01<00:00, 141.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4. Loss: 0.07734041661024094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 225/225 [00:01<00:00, 141.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5. Loss: 0.0645008236169815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 225/225 [00:01<00:00, 141.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6. Loss: 0.05797215923666954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 225/225 [00:01<00:00, 141.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7. Loss: 0.06194337457418442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 225/225 [00:01<00:00, 141.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8. Loss: 0.04426567628979683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 225/225 [00:01<00:00, 141.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9. Loss: 0.052392859011888504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2494/2494 [00:01<00:00, 1779.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLWWQ4phPxBB",
        "outputId": "f2d7659c-c156-4061-f59f-33dc7b1e1e79"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2494/2494 [00:01<00:00, 1730.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7u4xuuQeQq09"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}